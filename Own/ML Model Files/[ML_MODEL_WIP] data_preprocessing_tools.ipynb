{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Data Preprocessing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('synthetic_model_ready_data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entryId                             0\n",
       "customerEmail                       0\n",
       "transactionId                       0\n",
       "orderId                             0\n",
       "paymentMethodId                     0\n",
       "paymentMethodRegistrationFailure    0\n",
       "paymentMethodType                   0\n",
       "paymentMethodProvider               0\n",
       "transactionAmount                   0\n",
       "transactionFailed                   0\n",
       "orderState                          0\n",
       "customerPhone                       0\n",
       "customerDevice                      0\n",
       "customerIPAddress                   0\n",
       "customerBillingAddress              0\n",
       "No_Transactions                     0\n",
       "No_Orders                           0\n",
       "No_Payments                         0\n",
       "Fraud                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hCsz2yCebe1R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'dana09@yahoo.com' '3cryzmi3' ... 6 3 2]\n",
      " [2 'uchen@malone.com' 'yd80pfko' ... 7 7 6]\n",
      " [3 'meganberry@clark.biz' 'o4z2x2e9' ... 5 4 2]\n",
      " ...\n",
      " [11998 'johnlowery@gmail.com' 'i8ish28k' ... 6 4 3]\n",
      " [11999 'ybrown@gmail.com' '6p2l2jxb' ... 2 2 3]\n",
      " [12000 'johnlowery@gmail.com' 'iw7bakk3' ... 6 4 2]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eYrOQ43XcJR3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False ...  True False False]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c93k7ipkSexq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncode blocked since not applicable for the dataset\\n\\nQuestion for GPT: in the above code we are imputing 2nd and 3rd column who are next to each other. \\nwhat if I have a dataset with a mix of categorical and numerical data columns with missing values who are not next to each other?\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imputer.fit(X[:, 1:3])\n",
    "# X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "\n",
    "'''\n",
    "code blocked since not applicable for the dataset\n",
    "\n",
    "Question for GPT: in the above code we are imputing 2nd and 3rd column who are next to each other. \n",
    "what if I have a dataset with a mix of categorical and numerical data columns with missing values who are not next to each other?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3UgLdMS_bjq_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'dana09@yahoo.com' '3cryzmi3' ... 6 3 2]\n",
      " [2 'uchen@malone.com' 'yd80pfko' ... 7 7 6]\n",
      " [3 'meganberry@clark.biz' 'o4z2x2e9' ... 5 4 2]\n",
      " ...\n",
      " [11998 'johnlowery@gmail.com' 'i8ish28k' ... 6 4 3]\n",
      " [11999 'ybrown@gmail.com' '6p2l2jxb' ... 2 2 3]\n",
      " [12000 'johnlowery@gmail.com' 'iw7bakk3' ... 6 4 2]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhSpdQWeSsFh"
   },
   "source": [
    "### Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5hwuVddlSwVi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will not be using this process as we want to exclude \\nthe categorical data from the model and only work with the numerical data\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "# X = np.array(ct.fit_transform(X))\n",
    "\n",
    "'''\n",
    "We will not be using this process as we want to exclude \n",
    "the categorical data from the model and only work with the numerical data\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = dataset.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['customerEmail', 'transactionId', 'orderId', 'paymentMethodId', 'paymentMethodType', 'paymentMethodProvider', 'orderState', 'customerPhone', 'customerDevice', 'customerIPAddress', 'customerBillingAddress']\n",
      "Numerical columns: ['entryId', 'paymentMethodRegistrationFailure', 'transactionAmount', 'transactionFailed', 'No_Transactions', 'No_Orders', 'No_Payments']\n"
     ]
    }
   ],
   "source": [
    "# Print the identified categorical and numerical columns for verification\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After verifying the columns, enter the indices of numerical columns\n",
    "numerical_indices = [0, 5, 8, 9, 15, 16, 17]  # Enter the indices of numerical columns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer to only include the numerical columns\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('passthrough', 'passthrough', numerical_indices)  # Passthrough numerical columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the numerical features\n",
    "X_numerical = ct.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1     0    12 ...     6     3     2]\n",
      " [    2     0    59 ...     7     7     6]\n",
      " [    3     0    42 ...     5     4     2]\n",
      " ...\n",
      " [11998     0    65 ...     6     4     3]\n",
      " [11999     0    34 ...     2     2     3]\n",
      " [12000     1    33 ...     6     4     2]]\n"
     ]
    }
   ],
   "source": [
    "print(X_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "f7QspewyeBfx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1     0    12 ...     6     3     2]\n",
      " [    2     0    59 ...     7     7     6]\n",
      " [    3     0    42 ...     5     4     2]\n",
      " ...\n",
      " [11998     0    65 ...     6     4     3]\n",
      " [11999     0    34 ...     2     2     3]\n",
      " [12000     1    33 ...     6     4     2]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XgHCShVyTOYY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FyhY8-gPpFCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GuwQhFdKrYTM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7591    0   68 ...    3    3    1]\n",
      " [2902    0   47 ...    8    4    6]\n",
      " [3462    0   14 ...    4    4    4]\n",
      " ...\n",
      " [ 906    0   15 ...    8    5    2]\n",
      " [5193    0   13 ...    1    5    1]\n",
      " [ 236    1   74 ...    6    6    1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TUrX_Tvcrbi4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7164     1    42 ...     4     5     3]\n",
      " [10386     0    19 ...     4     3     1]\n",
      " [ 1903     0    16 ...     5     4     2]\n",
      " ...\n",
      " [ 5216     0    21 ...     6     0     2]\n",
      " [ 1006     0    29 ...     6     5     2]\n",
      " [ 8107     0    43 ...     2     3     1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pSMHiIsWreQY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "I_tW7H56rgtW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWPET8ZdlMnu"
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTXykB_QlRjE"
   },
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOihYlX/ooG5h+qw0sLIjn8",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

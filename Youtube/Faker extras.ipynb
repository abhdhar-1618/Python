{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d44ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9a0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('words.csv', index_col='Word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd67f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Char Count</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aahed</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Char Count  Value\n",
       "Word                    \n",
       "a               1      1\n",
       "aa              2      2\n",
       "aaa             3      3\n",
       "aah             3     10\n",
       "aahed           5     19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0308feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 370103 entries, a to zyzzyvas\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   Char Count  370103 non-null  int64\n",
      " 1   Value       370103 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a4ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude: -46.273434, Longitude: -19.401331\n",
      "Latitude: 15.601167, Longitude: -108.902391\n",
      "Latitude: 48.8973965, Longitude: 81.428509\n",
      "Latitude: 84.3967575, Longitude: 152.018482\n",
      "Latitude: -81.2034145, Longitude: 60.217640\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Generate a list of 1000 latitude and longitude pairs\n",
    "num_points = 1000\n",
    "coordinates = [(fake.latitude(), fake.longitude()) for _ in range(num_points)]\n",
    "\n",
    "# Print the first few coordinates\n",
    "for i in range(5):\n",
    "    print(f\"Latitude: {coordinates[i][0]}, Longitude: {coordinates[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be70c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates saved to D:\\Main\\My Practice and experiments\\YOUTUBE\\Python\\Libraries\\coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Generate a list of 1000 latitude and longitude pairs\n",
    "num_points = 1000\n",
    "coordinates = [(fake.latitude(), fake.longitude()) for _ in range(num_points)]\n",
    "\n",
    "# Save coordinates to a CSV file in the current working directory\n",
    "csv_file_path = 'coordinates.csv'\n",
    "current_directory = os.getcwd()\n",
    "csv_file_path = os.path.join(current_directory, csv_file_path)\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write header\n",
    "    csv_writer.writerow(['Latitude', 'Longitude'])\n",
    "    \n",
    "    # Write coordinates\n",
    "    csv_writer.writerows(coordinates)\n",
    "\n",
    "print(f\"Coordinates saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186670f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the dictionary: 370105\n",
      "Example words:\n",
      "['a', 'aa', 'aaa', 'aah', 'aahed', 'aahing', 'aahs', 'aal', 'aalii', 'aaliis']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Download the corncob list\n",
    "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Extract words from the response text\n",
    "    words = response.text.splitlines()\n",
    "    print(f\"Number of words in the dictionary: {len(words)}\")\n",
    "\n",
    "    # Print the first 10 words as an example\n",
    "    print(\"Example words:\")\n",
    "    print(words[:10])\n",
    "else:\n",
    "    print(\"Failed to download the dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57f5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words saved to CSV: 370105\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# Download the corncob list\n",
    "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Extract words from the response text\n",
    "    words = response.text.splitlines()\n",
    "\n",
    "    # Save words to a CSV file\n",
    "    csv_file_path = 'english_words.csv'\n",
    "\n",
    "    with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Word'])  # Write header\n",
    "\n",
    "        for word in words:\n",
    "            csv_writer.writerow([word])\n",
    "\n",
    "    print(f\"Number of words saved to CSV: {len(words)}\")\n",
    "else:\n",
    "    print(\"Failed to download the dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ff6d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b c d e f g h i j k l m n o p q r s t u v w x y z\n"
     ]
    }
   ],
   "source": [
    "word = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "separated_word = ' '.join(word)\n",
    "print(separated_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4cd1b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Main/YOUTUBE/Python/Libraries/english_words.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Main/YOUTUBE/Python/Libraries/english_words.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your CSV file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file_path, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     12\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(csvfile)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Create a list to store the processed data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Main/YOUTUBE/Python/Libraries/english_words.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to calculate the value of a word\n",
    "def calculate_value(word):\n",
    "    return sum(ord(char) - ord('a') + 1 for char in word.lower())\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file_path = 'D:/Main/YOUTUBE/Python/Libraries/english_words.csv'  # Replace with the path to your CSV file\n",
    "output_file_path = 'output.csv'\n",
    "\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    # Create a list to store the processed data\n",
    "    processed_data = []\n",
    "\n",
    "    # Process each row in the CSV\n",
    "    for row in reader:\n",
    "        word = row['Word']\n",
    "        char_count = len(word)\n",
    "        value = calculate_value(word)\n",
    "        \n",
    "        # Create a dictionary representing a row in the output\n",
    "        processed_row = {'Word': word, 'Char Count': char_count, 'Value': value}\n",
    "        processed_data.append(processed_row)\n",
    "\n",
    "# Write the processed data to a new CSV file\n",
    "with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Word', 'Char Count', 'Value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the processed data\n",
    "    for row in processed_data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Processed data has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20192057",
   "metadata": {},
   "source": [
    "-- import nltk\n",
    "\n",
    "-- nltk.download('wordnet')\n",
    "\n",
    "-- from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2307efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioms written to D:\\Main\\My Practice and experiments\\YOUTUBE\\Python\\Libraries\\english_idioms.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Get a list of English idioms\n",
    "idioms = wn.all_synsets(pos=wn.NOUN)\n",
    "english_idioms_nltk = [lemma.name().replace('_', ' ') for synset in idioms for lemma in synset.lemmas()]\n",
    "\n",
    "# Save idioms to CSV file in the same directory as the script\n",
    "csv_file_path = 'english_idioms.csv'\n",
    "script_directory = os.path.dirname(os.path.abspath('__file__'))\n",
    "csv_file_path = os.path.join(script_directory, csv_file_path)\n",
    "\n",
    "# Write idioms to CSV file\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Idiom'])\n",
    "    csv_writer.writerows([[idiom] for idiom in english_idioms_nltk])\n",
    "\n",
    "print(f\"Idioms written to {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
